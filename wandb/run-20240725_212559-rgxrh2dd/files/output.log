07/25/2024 21:26:04 - INFO - __main__ - ***** Running training *****
07/25/2024 21:26:04 - INFO - __main__ -   Num examples = 1706868
07/25/2024 21:26:04 - INFO - __main__ -   Num Epochs = 2
07/25/2024 21:26:04 - INFO - __main__ -   Instantaneous batch size per device = 2
07/25/2024 21:26:04 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 2
07/25/2024 21:26:04 - INFO - __main__ -   Gradient Accumulation steps = 1
07/25/2024 21:26:04 - INFO - __main__ -   Total optimization steps = 1000000
Steps:   0%|                                                                                                                                                                      | 0/1000000 [00:00<?, ?it/s]
Current process is using device: 0
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
encoder_hidden_states torch.Size([2, 40, 768])
Steps:   0%|                                                                                                                                                         | 1/1000000 [00:22<6184:11:46, 22.26s/it]07/25/2024 21:26:26 - INFO - accelerate.accelerator - Saving current state to /data/home/fundwotsai/test_AP/AP-adapter/audioldm2-large-ipadapter-audioset-unet-random-pooling_v4/checkpoint-1
07/25/2024 21:26:27 - INFO - accelerate.checkpointing - Model weights saved in /data/home/fundwotsai/test_AP/AP-adapter/audioldm2-large-ipadapter-audioset-unet-random-pooling_v4/checkpoint-1/model.safetensors
07/25/2024 21:26:28 - INFO - accelerate.checkpointing - Optimizer state saved in /data/home/fundwotsai/test_AP/AP-adapter/audioldm2-large-ipadapter-audioset-unet-random-pooling_v4/checkpoint-1/optimizer.bin
07/25/2024 21:26:28 - INFO - accelerate.checkpointing - Scheduler state saved in /data/home/fundwotsai/test_AP/AP-adapter/audioldm2-large-ipadapter-audioset-unet-random-pooling_v4/checkpoint-1/scheduler.bin
07/25/2024 21:26:28 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /data/home/fundwotsai/test_AP/AP-adapter/audioldm2-large-ipadapter-audioset-unet-random-pooling_v4/checkpoint-1/sampler.bin
07/25/2024 21:26:28 - INFO - accelerate.checkpointing - Random states saved in /data/home/fundwotsai/test_AP/AP-adapter/audioldm2-large-ipadapter-audioset-unet-random-pooling_v4/checkpoint-1/random_states_0.pkl
07/25/2024 21:26:28 - INFO - __main__ - Saved state to /data/home/fundwotsai/test_AP/AP-adapter/audioldm2-large-ipadapter-audioset-unet-random-pooling_v4/checkpoint-1
07/25/2024 21:26:28 - INFO - __main__ - Running validation...
 Generating 1 audio files with prompt: my Speech recording.
validation_prompt: my Speech recording
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
Forward upsample size to force interpolation output size.
Traceback (most recent call last):
  File "/data/home/fundwotsai/test_AP/AP-adapter/train_apadapter_v2.py", line 1051, in <module>
    main()
  File "/data/home/fundwotsai/test_AP/AP-adapter/train_apadapter_v2.py", line 1017, in main
    audios = log_validation(
             ^^^^^^^^^^^^^^^
  File "/data/home/fundwotsai/test_AP/AP-adapter/train_apadapter_v2.py", line 522, in log_validation
    audio_gen = pipeline(audio_file = random_file, prompt = args.validation_prompt,negative_prompt = "worst quality, low quality",num_inference_steps=50,audio_length_in_s=10.0,time_pooling = pooling_rate,freq_pooling = pooling_rate).audios[0]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/fundwotsai/test_AP/AP-adapter/pipeline/pipeline_audioldm2.py", line 1010, in __call__
    noise_pred = self.unet(
                 ^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/diffusers/pipelines/audioldm2/modeling_audioldm2.py", line 803, in forward
    sample, res_samples = downsample_block(
                          ^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/diffusers/pipelines/audioldm2/modeling_audioldm2.py", line 1147, in forward
    hidden_states = self.attentions[i * num_attention_per_layer + idx](
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/diffusers/models/transformer_2d.py", line 315, in forward
    hidden_states = block(
                    ^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/diffusers/models/attention.py", line 197, in forward
    attn_output = self.attn1(
                  ^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/diffusers/models/attention_processor.py", line 420, in forward
    return self.processor(
           ^^^^^^^^^^^^^^^
  File "/data/home/fundwotsai/test_AP/AP-adapter/APadapter/ap_adapter/attention_processor.py", line 280, in __call__
    hidden_states = attn.to_out[0](hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/miniconda3/envs/apadpter/lib/python3.11/site-packages/diffusers/models/lora.py", line 222, in forward
    def forward(self, hidden_states, scale: float = 1.0):
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])
encoder_hidden_states torch.Size([2, 520, 768])