04/25/2024 09:19:08 - INFO - __main__ - ***** Running training *****
04/25/2024 09:19:08 - INFO - __main__ -   Num examples = 239535
04/25/2024 09:19:08 - INFO - __main__ -   Num Epochs = 134
04/25/2024 09:19:08 - INFO - __main__ -   Instantaneous batch size per device = 8
04/25/2024 09:19:08 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32
04/25/2024 09:19:08 - INFO - __main__ -   Gradient Accumulation steps = 4
04/25/2024 09:19:08 - INFO - __main__ -   Total optimization steps = 1000000
Steps:   0%|                                                                                                                                                           | 0/1000000 [00:00<?, ?it/s]
Current process is using device: 0
batch[mel] torch.Size([8, 1, 1024, 64])
noisy_latents.shape torch.Size([8, 8, 256, 16])

Steps:   0%|                                                                                                                                    | 0/1000000 [00:45<?, ?it/s, loss=0.106, lr=0.0001]

Steps:   0%|                                                                                                                                   | 0/1000000 [00:49<?, ?it/s, loss=0.0996, lr=0.0001]
batch[mel] torch.Size([8, 1, 1024, 64])
noisy_latents.shape torch.Size([8, 8, 256, 16])


Steps:   0%|                                                                                                                      | 1/1000000 [00:55<15435:55:04, 55.57s/it, loss=0.135, lr=0.0001]
noisy_latents.shape torch.Size([8, 8, 256, 16])
batch[mel] torch.Size([8, 1, 1024, 64])
Steps:   0%|                                                                                                                      | 1/1000000 [00:55<15435:55:04, 55.57s/it, loss=0.135, lr=0.0001]Traceback (most recent call last):
  File "/home/fundwotsai/DreamSound/AP-adapter-full/train_ipadapter_v2.py", line 1723, in <module>
    main()
  File "/home/fundwotsai/DreamSound/AP-adapter-full/train_ipadapter_v2.py", line 1578, in main
    model_pred = unet(
                 ^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/DreamSound/AP-adapter-full/train_ipadapter_v2.py", line 1125, in forward
    return audioldmpipeline.unet(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/diffusers/pipelines/audioldm2/modeling_audioldm2.py", line 857, in forward
    sample = upsample_block(
             ^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/diffusers/models/unet_2d_blocks.py", line 2316, in forward
    hidden_states = resnet(hidden_states, temb, scale=scale)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/diffusers/models/resnet.py", line 608, in forward
    hidden_states = self.nonlinearity(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 396, in forward
    return F.silu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fundwotsai/anaconda3/envs/DreamSound/lib/python3.11/site-packages/torch/nn/functional.py", line 2059, in silu
    return torch._C._nn.silu(input)
           ^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 23.69 GiB total capacity; 18.67 GiB already allocated; 30.00 MiB free; 18.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF